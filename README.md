# Cloud-Based Distributed Data Processing Service

This project implements a cloud-based distributed data processing and analytics
system using Apache Spark on the Databricks platform. The system demonstrates
practical concepts of cloud computing and distributed data processing.

## Project Overview
The application allows users to upload a CSV dataset, perform data analysis,
apply multiple machine learning models, and evaluate performance in a cloud
environment. All processing tasks are executed using Apache Spark with PySpark.

## Technologies Used
- Apache Spark (PySpark)
- Databricks Cloud Platform
- Spark MLlib
- GitHub

## Implemented Features
- Dataset upload and cloud-based storage
- Descriptive data analysis (rows, columns, missing values, summary statistics)
- Machine learning models:
  - Linear Regression
  - Decision Tree Regression
  - KMeans Clustering
  - Logistic Regression (Classification)
- Performance evaluation using execution time, speedup, and efficiency metrics
- Unified results integration and presentation

## How to Run the Project
1. Open the Databricks notebook using the provided link.
2. Upload the dataset (CSV file) to the Databricks platform.
3. Run the notebook cells sequentially.
4. View analysis results and machine learning outputs directly in the notebook.


## Repository Contents
- `project_notebook.ipynb` – Databricks notebook containing the full implementation
- `report.pdf` – Full project report
- `README.md` – Project description and usage instructions

## Notes
- Accessing the Databricks notebook requires a Databricks account.
- The project is designed for educational purposes as part of a cloud and
  distributed systems course.
